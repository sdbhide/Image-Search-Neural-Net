# Image-Search-Neural-Net
Neural network models which aim to build an image searching tool from scratch

This project aims to develop a lightweight, modular neural model for multimodal retrieval from scratch, without relying on pretrained encoders. The system is designed to handle three core tasks:

1. Retrieving relevant images from text queries
2. Enabling image-to-image retrieval through caption generation
3. Learning a shared embedding space for unified cross-modal retrieval.

This approach provides a deeper understanding of the mechanics of sentence-image alignment while offering the potential for multilingual and customizable extensions in the future.
